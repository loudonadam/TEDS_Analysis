{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic cleaning function\n",
    "def clean_data(file_path, ted_variables, services_values, reason_values):\n",
    "\n",
    "    # Load .csv file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Select columns\n",
    "    teds_reduced_df = df[ted_variables]\n",
    "\n",
    "    # Remove value 6 'Death' from Reason column \n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 6]\n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 5]\n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 7]\n",
    "    # Remove value 4 'Transferred to another treatment program' from Reason column \n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 4]\n",
    "\n",
    "    # Add sucessful column equal copied from REASON columnto 1 based on passed list reasons_values and the rest to 0\n",
    "    teds_reduced_df['SUCCESSFUL'] = teds_reduced_df['REASON']\n",
    "\n",
    "    # Change values in SUCCESSFUL column to 1 for passed list of reason_values chosen to indicate successful outcome\n",
    "    for reason in reason_values:\n",
    "        teds_reduced_df['SUCCESSFUL'] = teds_reduced_df['SUCCESSFUL'].replace({reason: 1}).astype(int) \n",
    "    \n",
    "    # Change all other values in SUCCESSFUL column that aren't 1 to un sucessful 0.\n",
    "    teds_reduced_df.loc[teds_reduced_df.SUCCESSFUL != 1, 'SUCCESSFUL'] = 0\n",
    "\n",
    "    # Filter for AGES 18 and older.  Values > 2 based on codebook\n",
    "    teds_clean = teds_reduced_df[teds_reduced_df.AGE > 2]\n",
    "    \n",
    "    # Take out all rows with value -9 (Missing/unknown/not collected/invalid) in any column\n",
    "    teds_clean = teds_clean.replace({-9: np.nan}).dropna().astype(int)\n",
    "\n",
    "    # Comnine race values 1,3,6,9 that are less than 1% to a new value of 10. Keep values 2, 4, 5, 7, 8 as is.\n",
    "    races = [1,3,6,9]\n",
    "    for race in races:\n",
    "        teds_clean['RACE'] = teds_clean['RACE'].replace({race: 10}).astype(int) \n",
    "\n",
    "    # SERVICES column: select outpatient treatment, values 6 and 7,  Rhab values 2, 4, 5, \n",
    "    teds_clean = teds_clean[teds_clean[\"SERVICES\"].isin(services_values)]\n",
    "\n",
    "    # Return clean data frame\n",
    "    return teds_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to import dataset\n",
    "# def load_data(file_path):\n",
    "\n",
    "#     # Read dataset into dataframe \n",
    "#     teds_cleaned_df = pd.read_csv(file_path)\n",
    "\n",
    "#     return teds_cleaned_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split our preprocessed data into our features and target arrays.  Get training and testing values and scale.\n",
    "def prepare_data(teds_cleaned_df):\n",
    "    \n",
    "    # Split our preprocessed data into our features and target arrays\n",
    "    y = teds_cleaned_df[\"SUCCESSFUL\"].values\n",
    "    X = teds_cleaned_df.drop([\"REASON\",\"SUCCESSFUL\"],axis=1).values\n",
    "\n",
    "    # Split the preprocessed data into a training and testing dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78, stratify=y)\n",
    "\n",
    "    # Create a StandardScaler instance\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit the StandardScaler\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "\n",
    "    # Scale the traingin and test data\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Scale the full dataset \n",
    "    X_test_full_scaled = X_scaler.transform(X)\n",
    "\n",
    "    return X_train_scaled, y_train, X_test_scaled, y_test, X_test_full_scaled, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function  - deep neural net\n",
    "def define_model(number_input_features, hidden_nodes_layer1, hidden_nodes_layer2):\n",
    "    keras.backend.clear_session()\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # First hidden layer\n",
    "    nn.add(\n",
    "        tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    "    )\n",
    "\n",
    "    # Second hidden layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))  \n",
    "\n",
    "    # Output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISYR</th>\n",
       "      <th>VET</th>\n",
       "      <th>REGION</th>\n",
       "      <th>FREQ_ATND_SELF_HELP</th>\n",
       "      <th>PSYPROB</th>\n",
       "      <th>DSMCRIT</th>\n",
       "      <th>ALCDRUG</th>\n",
       "      <th>PSOURCE</th>\n",
       "      <th>NOPRIOR</th>\n",
       "      <th>AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>ALCFLG</th>\n",
       "      <th>COKEFLG</th>\n",
       "      <th>MARFLG</th>\n",
       "      <th>MTHAMFLG</th>\n",
       "      <th>LOS</th>\n",
       "      <th>OPSYNFLG</th>\n",
       "      <th>HERFLG</th>\n",
       "      <th>FREQ1</th>\n",
       "      <th>REASON</th>\n",
       "      <th>SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DISYR  VET  REGION  FREQ_ATND_SELF_HELP  PSYPROB  DSMCRIT  ALCDRUG  \\\n",
       "248   2019    2       4                    1        1        5        2   \n",
       "251   2019    2       4                    5        1        5        3   \n",
       "257   2019    2       4                    1        1        4        1   \n",
       "261   2019    2       4                    1        1        4        1   \n",
       "277   2019    2       4                    1        2        4        3   \n",
       "\n",
       "     PSOURCE  NOPRIOR  AGE  ...  ALCFLG  COKEFLG  MARFLG  MTHAMFLG  LOS  \\\n",
       "248        3        1    6  ...       0        0       1         1   12   \n",
       "251        1        1    5  ...       1        0       0         1   32   \n",
       "257        1        1    9  ...       1        0       0         0   32   \n",
       "261        1        1    6  ...       1        0       0         0   14   \n",
       "277        1        1   11  ...       1        0       1         0    8   \n",
       "\n",
       "     OPSYNFLG  HERFLG  FREQ1  REASON  SUCCESSFUL  \n",
       "248         0       1      3       2           0  \n",
       "251         0       1      2       1           1  \n",
       "257         0       0      3       2           0  \n",
       "261         0       0      3       2           0  \n",
       "277         0       0      3       2           0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get clean data \n",
    "\n",
    "# Create file path list for input datasets\n",
    "file_path_2015 = Path('Resources/tedsd_2015_puf.csv')\n",
    "file_path_2016 = Path('Resources/tedsd_2016_puf.csv')\n",
    "file_path_2017 = Path('Resources/tedsd_puf_2017.csv')\n",
    "file_path_2018 = Path('Resources/tedsd_puf_2018.csv')\n",
    "file_path_2019 = Path('Resources/tedsd_puf_2019.csv')\n",
    "file_paths = [file_path_2015, file_path_2016, file_path_2017, file_path_2018, file_path_2019]\n",
    "\n",
    "# Create output file path list to export cleaned dataframes to .csv files \n",
    "output_file_path_2015 = Path('Resources/teds_2015_cleaned.csv')\n",
    "output_file_path_2016 = Path('Resources/teds_2016_cleaned.csv')\n",
    "output_file_path_2017 = Path('Resources/teds_2017_cleaned.csv')\n",
    "output_file_path_2018 = Path('Resources/teds_2018_cleaned.csv')\n",
    "output_file_path_2019 = Path('Resources/teds_2019_cleaned.csv')\n",
    "output_file_paths = [output_file_path_2015, output_file_path_2016, output_file_path_2017, output_file_path_2018, output_file_path_2019]\n",
    "\n",
    "# Select features to use for analysis.  Must include 'SERVICES and 'REASON' \n",
    "ted_variables = ['DISYR', 'VET', 'REGION', 'FREQ_ATND_SELF_HELP', 'PSYPROB', 'DSMCRIT', 'ALCDRUG', 'PSOURCE', 'NOPRIOR', 'AGE',\n",
    "                'RACE', 'GENDER', 'EDUC', 'MARSTAT', 'EMPLOY', 'LIVARAG', 'SERVICES', 'SUB1', 'SUB2','ROUTE1', 'FRSTUSE1', 'ALCFLG', \n",
    "                'COKEFLG', 'MARFLG', 'MTHAMFLG', 'LOS', 'OPSYNFLG', 'HERFLG', 'FREQ1', 'REASON']\n",
    "\n",
    "# Select treatment services for analysis.  Values 6,7 are outpatient.  Values 3,4,5 are in patient.  Values 1,2 are 24 hour detox\n",
    "services_values = [4,5] \n",
    "\n",
    "# Select values from REASON column to combine to a value of 1 for the target column SUCCESSFUL.  Must be a combination of 1,4,7.\n",
    "reason_values = [1]\n",
    "\n",
    "# Clean data with clean_data function with specified variables \n",
    "teds_cleaned_df = clean_data(file_path_2019, ted_variables, services_values, reason_values)\n",
    "teds_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    74939\n",
       "0    44388\n",
       "Name: SUCCESSFUL, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds_cleaned_df['SUCCESSFUL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop thru Epochs and Class Weights to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs 5\n",
      "\n",
      "\n",
      "Weight 0.3\n",
      "Testing Loss: 0.5945817828178406, Testing Accuracy: 0.6898967623710632\n",
      "Training Loss: 0.5925002694129944, Training Accuracy: 0.6906084418296814\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         9524         1573\n",
      "Actual 1         7678        11057\n",
      "Precision: 0.8754552652414885\n",
      "\n",
      "Testing Loss full dataset: 0.5930198431015015, Testing Accuracy full dataset: 0.6904305219650269\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        38314         6074\n",
      "Actual 1        30866        44073\n",
      "Precision: 0.8788761042534947\n",
      "\n",
      "\n",
      "Weight 0.4\n",
      "Testing Loss: 0.5371071696281433, Testing Accuracy: 0.7292169332504272\n",
      "Training Loss: 0.5323128700256348, Training Accuracy: 0.7339404225349426\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         9078         2019\n",
      "Actual 1         6059        12676\n",
      "Precision: 0.8626063286832256\n",
      "\n",
      "Testing Loss full dataset: 0.5335120558738708, Testing Accuracy full dataset: 0.7327595353126526\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        36573         7815\n",
      "Actual 1        24074        50865\n",
      "Precision: 0.8668200408997955\n",
      "\n",
      "\n",
      "Weight 0.5\n",
      "Testing Loss: 0.5127021670341492, Testing Accuracy: 0.7427259087562561\n",
      "Training Loss: 0.5066936016082764, Training Accuracy: 0.7475389838218689\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         8772         2325\n",
      "Actual 1         5350        13385\n",
      "Precision: 0.8520050922978994\n",
      "\n",
      "Testing Loss full dataset: 0.5081952810287476, Testing Accuracy full dataset: 0.7463356852531433\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        35320         9068\n",
      "Actual 1        21201        53738\n",
      "Precision: 0.8556188899149763\n",
      "\n",
      "\n",
      "Weight 0.6\n",
      "Testing Loss: 0.48849037289619446, Testing Accuracy: 0.7683359980583191\n",
      "Training Loss: 0.48280757665634155, Training Accuracy: 0.7691379189491272\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0         8121         2976\n",
      "Actual 1         3935        14800\n",
      "Precision: 0.8325832583258326\n",
      "\n",
      "Testing Loss full dataset: 0.48422837257385254, Testing Accuracy full dataset: 0.7689374685287476\n",
      "          Predicted 0  Predicted 1\n",
      "Actual 0        32493        11895\n",
      "Actual 1        15677        59262\n",
      "Precision: 0.8328344365276782\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for model\n",
    "X_train_scaled, y_train, X_test_scaled, y_test, X_test_full_scaled, y = prepare_data(teds_cleaned_df)\n",
    "\n",
    "# Define neural network model parameters\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "# Get the model based defined parameters\n",
    "nn = define_model(number_input_features, hidden_nodes_layer1, hidden_nodes_layer2)\n",
    "\n",
    "# Check the structure of the model\n",
    "# nn.summary()\n",
    "\n",
    "# Loop to evaluate model performance vs epoch number and weight values\n",
    "# Set the values of the epochs list to see the effect on model perfomance\n",
    "epoch_list = [5]\n",
    "\n",
    "# Define empty dataframe to hold model evaluation results for training and testing results\n",
    "nn_model_results_wt = pd.DataFrame(columns = ['Weight', 'Training loss', 'Training accuracey', 'Testing loss',\n",
    "                                'Testing accuracy', 'Testing Precision']) \n",
    "\n",
    "# Define empty data frame to hold model evaluation results on entire dataset\n",
    "nn_model_results_wt_fd = pd.DataFrame(columns = ['Weight', 'Testing loss',\n",
    "                                'Testing accuracy', 'Precision']) \n",
    "\n",
    "for ep in epoch_list:\n",
    "    print(f\"\\nEpochs {ep}\")\n",
    "\n",
    "    # Define weight values to evaluate model \n",
    "    wts = [.3, .4, .5, .6]\n",
    "    # wts = [.4]\n",
    "\n",
    "    # Loop through weights list to determine optimal weighting for model fit\n",
    "    for wt in wts:\n",
    "        print(f\"\\n\\nWeight {wt}\")\n",
    "        weights = {0:1, 1:wt}\n",
    "        fit_model = nn.fit(X_train_scaled,y_train, class_weight=weights, epochs=ep, verbose=0)\n",
    "\n",
    "        # Evaluate the model using the test data\n",
    "        model_loss_test, model_accuracy_test = nn.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "        print(f\"Testing Loss: {model_loss_test}, Testing Accuracy: {model_accuracy_test}\")\n",
    "\n",
    "        # Evaluate the model using the training data\n",
    "        model_loss_train, model_accuracy_train = nn.evaluate(X_train_scaled,y_train,verbose=0)\n",
    "        print(f\"Training Loss: {model_loss_train}, Training Accuracy: {model_accuracy_train}\")\n",
    "\n",
    "        # Get confusion matrix\n",
    "        y_pred = nn.predict(X_test_scaled)\n",
    "        confusion_matrix = sklearn.metrics.confusion_matrix(y_test, np.rint(y_pred))\n",
    "        \n",
    "        # Create a DataFrame from the confusion matrix.\n",
    "        nn_cm_df = pd.DataFrame(\n",
    "            confusion_matrix, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "        print(nn_cm_df)\n",
    "\n",
    "        # Export confusion matrix to .csv file per weight\n",
    "        nn_cm_wt_filename = 'Resources/ML_model_results/nn_cm_wt_' + str(wt) +'.csv'\n",
    "        output_path = Path(nn_cm_wt_filename)\n",
    "        nn_cm_df.to_csv(output_path, encoding='utf-8')\n",
    "        \n",
    "        # Calculate precision \n",
    "        tp = nn_cm_df.loc['Actual 1', 'Predicted 1']\n",
    "        fp = nn_cm_df.loc['Actual 0', 'Predicted 1']\n",
    "        precision = tp / (tp+fp)\n",
    "        print(f\"Precision: {precision}\")\n",
    "\n",
    "        # Store training and testing data to dataframe\n",
    "        nn_model_results_wt.loc[len(nn_model_results_wt)] = [wt, model_loss_train, model_accuracy_train, \n",
    "                                                    model_loss_test, model_accuracy_test, precision]\n",
    "\n",
    "        # Evaluate the model using the full dataset\n",
    "        model_loss, model_accuracy = nn.evaluate(X_test_full_scaled,y,verbose=0)\n",
    "        print(f\"\\nTesting Loss full dataset: {model_loss}, Testing Accuracy full dataset: {model_accuracy}\")\n",
    "        \n",
    "        # Get confusion matrix\n",
    "        y_pred = nn.predict(X_test_full_scaled)\n",
    "        confusion_matrix = sklearn.metrics.confusion_matrix(y, np.rint(y_pred))\n",
    "\n",
    "        # Create a DataFrame from the confusion matrix.\n",
    "        nn_cm_df = pd.DataFrame(\n",
    "            confusion_matrix, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "        print(nn_cm_df)\n",
    "\n",
    "        # Export confusion matrix for full dataset run per weight\n",
    "        nn_cm_full_wt_filename = 'Resources/ML_model_results/nn_cm_full_wt' + str(wt) +'.csv'\n",
    "        output_path = Path(nn_cm_full_wt_filename)\n",
    "        nn_cm_df.to_csv(output_path, encoding='utf-8')\n",
    "\n",
    "        tp = nn_cm_df.loc['Actual 1', 'Predicted 1']\n",
    "        fp = nn_cm_df.loc['Actual 0', 'Predicted 1']\n",
    "        precision = tp / (tp+fp)\n",
    "        print(f\"Precision: {precision}\")\n",
    "\n",
    "        nn_model_results_wt_fd.loc[len(nn_model_results_wt_fd)] = [wt, model_loss, model_accuracy, precision]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Training loss</th>\n",
       "      <th>Training accuracey</th>\n",
       "      <th>Testing loss</th>\n",
       "      <th>Testing accuracy</th>\n",
       "      <th>Testing Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.592500</td>\n",
       "      <td>0.690608</td>\n",
       "      <td>0.594582</td>\n",
       "      <td>0.689897</td>\n",
       "      <td>0.875455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.532313</td>\n",
       "      <td>0.733940</td>\n",
       "      <td>0.537107</td>\n",
       "      <td>0.729217</td>\n",
       "      <td>0.862606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.506694</td>\n",
       "      <td>0.747539</td>\n",
       "      <td>0.512702</td>\n",
       "      <td>0.742726</td>\n",
       "      <td>0.852005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.482808</td>\n",
       "      <td>0.769138</td>\n",
       "      <td>0.488490</td>\n",
       "      <td>0.768336</td>\n",
       "      <td>0.832583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Training loss  Training accuracey  Testing loss  Testing accuracy  \\\n",
       "0     0.3       0.592500            0.690608      0.594582          0.689897   \n",
       "1     0.4       0.532313            0.733940      0.537107          0.729217   \n",
       "2     0.5       0.506694            0.747539      0.512702          0.742726   \n",
       "3     0.6       0.482808            0.769138      0.488490          0.768336   \n",
       "\n",
       "   Testing Precision  \n",
       "0           0.875455  \n",
       "1           0.862606  \n",
       "2           0.852005  \n",
       "3           0.832583  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show model results vs weight values\n",
    "nn_model_results_wt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Testing loss</th>\n",
       "      <th>Testing accuracy</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.593020</td>\n",
       "      <td>0.690431</td>\n",
       "      <td>0.878876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.533512</td>\n",
       "      <td>0.732760</td>\n",
       "      <td>0.866820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.508195</td>\n",
       "      <td>0.746336</td>\n",
       "      <td>0.855619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.484228</td>\n",
       "      <td>0.768937</td>\n",
       "      <td>0.832834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Weight  Testing loss  Testing accuracy  Precision\n",
       "0     0.3      0.593020          0.690431   0.878876\n",
       "1     0.4      0.533512          0.732760   0.866820\n",
       "2     0.5      0.508195          0.746336   0.855619\n",
       "3     0.6      0.484228          0.768937   0.832834"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show model results tested on full dataset\n",
    "nn_model_results_wt_fd.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab315c993c9ef262b9a58319d7b32fd1261371ea3469adebec2e3c23752144c9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mlenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
