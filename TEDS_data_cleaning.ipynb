{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cleaning function to clean the dataframe based on variables to select column features, to select the type of service (inpatient or outpatient), file path location of the data, and the reason values to be combined in the creation of the successful target column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic cleaning function\n",
    "def clean_data(file_path, ted_variables, services_values, reason_values):\n",
    "\n",
    "    # Load .csv file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Select columns\n",
    "    teds_reduced_df = df[ted_variables]\n",
    "\n",
    "    # Remove values 4(Transferred),5(incarcerated),6(Death),7(other)  from Reason column\n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 4]\n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 5]\n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 6]\n",
    "    teds_reduced_df = teds_reduced_df[teds_reduced_df.REASON != 7]\n",
    "\n",
    "    # Add sucessful column equal copied from REASON columnto 1 based on passed list reasons_values and the rest to 0\n",
    "    teds_reduced_df['SUCCESSFUL'] = teds_reduced_df['REASON']\n",
    "\n",
    "    # Change values in SUCCESSFUL column to 1 for passed list of reason_values chosen to indicate successful outcome\n",
    "    for reason in reason_values:\n",
    "        teds_reduced_df['SUCCESSFUL'] = teds_reduced_df['SUCCESSFUL'].replace({reason: 1}).astype(int) \n",
    "    \n",
    "    # Change all other values in SUCCESSFUL column that aren't 1 to un sucessful 0.\n",
    "    teds_reduced_df.loc[teds_reduced_df.SUCCESSFUL != 1, 'SUCCESSFUL'] = 0\n",
    "\n",
    "    # Filter for AGES 18 and older.  Values > 2 based on codebook\n",
    "    teds_clean = teds_reduced_df[teds_reduced_df.AGE > 2]\n",
    "    \n",
    "    # Take out all rows with value -9 (Missing/unknown/not collected/invalid) in any column\n",
    "    teds_clean = teds_clean.replace({-9: np.nan}).dropna().astype(int)\n",
    "\n",
    "    # Comnine race values 1,3,6,9 that are less than 1% to a new value of 10. Keep values 2, 4, 5, 7, 8 as is.\n",
    "    races = [1,3,6,9]\n",
    "    for race in races:\n",
    "        teds_clean['RACE'] = teds_clean['RACE'].replace({race: 10}).astype(int) \n",
    "\n",
    "    # SERVICES column: select outpatient treatment, values 6 and 7,  Rhab values 2, 4, 5, \n",
    "    teds_clean = teds_clean[teds_clean[\"SERVICES\"].isin(services_values)]\n",
    "\n",
    "    # Return clean data frame\n",
    "    return teds_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the parameters to specify the data cleaning and loop thru and Load the datasets from 2015 to 2019.  \n",
    "# Load Data, Clean, and Export to .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "# Create file path list for input datasets\n",
    "file_path_2015 = Path('Resources/tedsd_2015_puf.csv')\n",
    "file_path_2016 = Path('Resources/tedsd_2016_puf.csv')\n",
    "file_path_2017 = Path('Resources/tedsd_puf_2017.csv')\n",
    "file_path_2018 = Path('Resources/tedsd_puf_2018.csv')\n",
    "file_path_2019 = Path('Resources/tedsd_puf_2019.csv')\n",
    "file_paths = [file_path_2015, file_path_2016, file_path_2017, file_path_2018, file_path_2019]\n",
    "\n",
    "# Create output file path list to export cleaned dataframes to .csv files \n",
    "output_file_path_2015 = Path('Resources/teds_2015_cleaned.csv')\n",
    "output_file_path_2016 = Path('Resources/teds_2016_cleaned.csv')\n",
    "output_file_path_2017 = Path('Resources/teds_2017_cleaned.csv')\n",
    "output_file_path_2018 = Path('Resources/teds_2018_cleaned.csv')\n",
    "output_file_path_2019 = Path('Resources/teds_2019_cleaned.csv')\n",
    "output_file_paths = [output_file_path_2015, output_file_path_2016, output_file_path_2017, output_file_path_2018, output_file_path_2019]\n",
    "\n",
    "# Select features to use for analysis.  Must include 'SERVICES and 'REASON' \n",
    "ted_variables = ['DISYR', 'VET', 'REGION', 'FREQ_ATND_SELF_HELP', 'PSYPROB', 'DSMCRIT', 'ALCDRUG', 'PSOURCE', 'NOPRIOR', 'AGE',\n",
    "                'RACE', 'GENDER', 'EDUC', 'MARSTAT', 'EMPLOY', 'LIVARAG', 'SERVICES', 'SUB1', 'SUB2','ROUTE1', 'FRSTUSE1', 'ALCFLG', \n",
    "                'COKEFLG', 'MARFLG', 'MTHAMFLG', 'LOS', 'OPSYNFLG', 'HERFLG', 'FREQ1', 'REASON']\n",
    "\n",
    "# Select treatment services for analysis.  Values 6,7 are outpatient.  Values 3,4,5 are in patient.  Values 1,2 are 24 hour detox\n",
    "services_values = [4,5] \n",
    "\n",
    "# Select values from REASON column to combine to a value of 1 for the target column SUCCESSFUL.  Must be a combination of 1,4,7.\n",
    "reason_values = [1]\n",
    "\n",
    "# Loop thru and import dataset .csv files, Call clean data funtion to get cleaned data frame and output dataframes to .csv files\n",
    "# for machine learning model code\n",
    "for (file_path, output_file_path) in zip(file_paths, output_file_paths):\n",
    "    # Clean data with clean_data function with specified variables \n",
    "    teds_cleaned_df = clean_data(file_path, ted_variables, services_values, reason_values)\n",
    "    # Print DISYR column for year after each read \n",
    "    print(teds_cleaned_df.iat[0,0])\n",
    "    # Export cleaned dataframe to .csv file\n",
    "    teds_cleaned_df.to_csv(output_file_path, encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# # Code for exporting to SQL database commented out\n",
    "# # Import dependencies for SQL database export\n",
    "# from sqlalchemy import create_engine\n",
    "# from config import db_password\n",
    "# # Create connection to PostgreSQL database\n",
    "# db_string = f\"postgresql://postgres:{db_password}@127.0.0.1:5432/TEDS\"\n",
    "# engine = create_engine(db_string)\n",
    "# # Set SQL output table names\n",
    "# table_names = ['Teds_2015', 'Teds_2016', 'Teds_2017','Teds_2018','Teds_2019']\n",
    "\n",
    "# # Loop thru and import dataset .csv files, Call clean data funtion to get cleaned data frame and \n",
    "# # output dataframes to SQL database for machine learning model code\n",
    "# for (file_path, table_name) in zip(file_paths, table_names):\n",
    "#     # Clean data with clean_data function with specified variables \n",
    "#     teds_cleaned_df = clean_data(file_path, ted_variables, services_values, reason_values)\n",
    "#     # Print DISYR column for year after each read \n",
    "#     print(teds_cleaned_df.iat[0,0])\n",
    "#     # Add teds_clean dataframe to a SQL database\n",
    "#     teds_cleaned_df.to_sql(name=table_name, con=engine, index=False, if_exists='replace')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab315c993c9ef262b9a58319d7b32fd1261371ea3469adebec2e3c23752144c9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('mlenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
